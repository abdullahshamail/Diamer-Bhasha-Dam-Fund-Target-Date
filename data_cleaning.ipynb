{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework we'll be looking at the data released by the State Bank of Pakistan. The data is the daily bank-wise and donor-wise receipts of the fund for the Daimer Bhasha and Mohmand Dam. You can find them in the following link: http://www.sbp.org.pk/notifications/FD/DamFund/Damfund.htm. Take a moment to look around the data and try to figure out what the possible challenges could be.\n",
    "\n",
    "The main purpose of this homework is to teach how to scrape data from the web, clean it, and import it into Pandas for data analysis purposes. There are however some things to note:\n",
    "1. As you can tell, the data is in PDF form. PDF is the most difficult to handle data format and if you get extremely broken CSV files, there isn't a need to worry, that's where the cleaning part comes in.\n",
    "2. We'll be using an API to convert the data from PDF to CSV, and then from CSV to Pandas. There are, however, other ways to do this. The reason we wanted to do this method is two-fold\n",
    "    * It will teach you how to communicate with APIs using Python, which will be a useful skill when you want to deploy your data models as an API so that it can work with other APIs that need those data models. Moreover, a lot of data you get in the real world is from APIs. \n",
    "    * The CSV will be extremely inconsistent, so it will give you immense practice with using regular-expressions, which are extremely important in the Data Science tool-kit.\n",
    "    \n",
    "Submit the notebooks in a similar format to the Labs: print the relevant output in each cell **only if it has an output. The initial scraping and converting does not have any output**, and name the notebooks as:\n",
    "**rollnumber_HW1.ipynb** for e.g **20100237_H1.ipynb**\n",
    "\n",
    "Please make sure you complete full parts (denoted by a Header each in this notebook) as the grading will be based on parts. Needless to say, do not copy someone else's code. In most Data Science careers, the main skill is not how good you are at coding, but how well you are able to use the tools at your disposal and what inferences you are able to make with the information that you have. Thus, while you might be able to do the HW by looking at someone else's code, unless you go through the actual thought process, you won't learn a lot.\n",
    "\n",
    "We'll be using a lot of libraries in this tutorial, make sure you go through them so you understand what they are used for.\n",
    "\n",
    "**NOTE: If you are more comfortable doing so, as I am, you can do the assignment on your preferred text editor on simple Python and then write the code neatly in a notebook.** Personally, I find Sublime/Vim easier to use than Jupyter, mostly since a lot of shortcuts there make coding much easier, while here the shortcuts are more about navigation and controlling your cells.\n",
    "\n",
    "**The homework is to be done in pairs of 2.** \n",
    "\n",
    "**Naming convention: rollnumber1_rollnumber2_HW1.ipynb**\n",
    "\n",
    "Total Marks: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Getting the Data\n",
    "\n",
    "You can have a look at the data through the link given above. Download a few PDF files and go through the data to see what it looks like. How many columns are there, each, in the PDF files? Are there any inconsistencies? Any particular values that pop out that would need to be taken care of later in your cleaning? Think of all these questions when going through the initial PDF because they will prove really helpful when you can not figure out why there are so many \"NaN\" values in your final DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Scraping              \n",
    "Marks: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using what is called the *requests* model to get an HTML page, and then use *BeautifulSoup* to parse that HTML page such that we are able to to derive the appropriate information from it. I recommend you go through the documentation of each to learn more about how to use the libraries. \n",
    "\n",
    "* [Requests Documentation](http://docs.python-requests.org/en/master/)\n",
    "* [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [BeautifulSoup + Requests Tutorial](https://www.pythonforbeginners.com/python-on-the-web/web-scraping-with-beautifulsoup)\n",
    "* [BeautifulSoup](https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe) Note that this tutorial is more detailed. I would highly recommend you go through this as well even though the library used here is urllib2 instead of requests (which you can do as well!). It also links to more web-scraping libraries like Scrapy for more complicated scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "html_url = \"http://www.sbp.org.pk/notifications/FD/DamFund/Damfund.htm\"\n",
    "url = \"http://www.sbp.org.pk/notifications/FD/DamFund/\"\n",
    "\n",
    "html_page = requests.get(html_url)\n",
    "\n",
    "html_page.text\n",
    "\n",
    "soup = BeautifulSoup(html_page.text, 'html.parser')\n",
    "\n",
    "\n",
    "listOfPdfs=[]\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    if(link.get('href').startswith(\"Datewise\")):\n",
    "        listOfPdfs.append(link.get('href'))\n",
    "\n",
    "for i in range(len(listOfPdfs)):\n",
    "    listOfPdfs[i] = url + listOfPdfs[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-10-2018\n",
      "04-10-2018\n",
      "03-10-2018\n",
      "02-10-2018\n",
      "01-10-2018\n",
      "28-09-2018\n",
      "27-09-2018\n",
      "26-09-2018\n",
      "25-09-2018\n",
      "24-09-2018\n",
      "19-09-2018\n",
      "18-09-2018\n",
      "17-09-2018\n",
      "14-09-2018\n",
      "13-09-2018\n",
      "12-09-2018\n",
      "11-09-2018\n",
      "10-09-2018\n",
      "07-09-2018\n",
      "06-09-2018\n",
      "05-09-2018\n",
      "04-09-2018\n",
      "03-09-2018\n",
      "31-08-2018\n",
      "30-08-2018\n",
      "29-08-2018\n",
      "28-08-2018\n",
      "27-08-2018\n",
      "24-08-2018\n",
      "20-08-2018\n",
      "17-08-2018\n",
      "16-08-2018\n",
      "15-08-2018\n",
      "13-08-2018\n",
      "10-08-2018\n",
      "09-08-2018\n",
      "08-08-2018\n",
      "07-08-2018\n",
      "06-08-2018\n",
      "03-08-2018\n",
      "02-08-2018\n",
      "01-08-2018\n",
      "31-07-2018\n",
      "30-07-2018\n",
      "27-07-2018\n",
      "26-07-2018\n",
      "24-07-2018\n",
      "23-07-2018\n",
      "20-07-2018\n",
      "19-07-2018\n",
      "18-07-2018\n",
      "17-07-2018\n",
      "16-07-2018\n",
      "13-07-2018\n",
      "12-07-2018\n",
      "11-07-2018\n",
      "10-07-2018\n",
      "09-07-2018\n",
      "06-07-2018\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(listOfPdfs)):\n",
    "    nameToSet = (((listOfPdfs[i].split('/'))[-1]).split('.'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n",
      "Downloaded all Files\n"
     ]
    }
   ],
   "source": [
    "newpath = r'./allPdfs'\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.mkdir(newpath)\n",
    "else:\n",
    "    print (\"Directory already exists\")\n",
    "    \n",
    "    \n",
    "for i in range(len(listOfPdfs)):\n",
    "    addpdf = requests.get(listOfPdfs[i])\n",
    "    nameToSet = (((listOfPdfs[i].split('/'))[-1]).split('.'))[0]\n",
    "    with open(\"allPdfs/\"+nameToSet+\".pdf\", \"wb\") as f:\n",
    "        f.write(addpdf.content)\n",
    "\n",
    "print(\"Downloaded all Files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Converting from PDF to CSV\n",
    "Marks: 15\n",
    "\n",
    "You have two possible options between deciding what API to use for the conversion task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first option is communicating with an API called [Zamzar](https://www.zamzar.com) to send each PDF, ask them to convert it into CSV, and then download the converted CSV. They provide sample code to do everything from generating a simple request to starting a conversion job, checking for completion, and then downloading the finished file. You can find this information on the [Zamzar Documentation](https://developers.zamzar.com/docs) page.\n",
    "\n",
    "**Important Information: **\n",
    "\n",
    "The API only provides 100 points of free conversion, and each PDF to CSV conversion costs 3 points, that means with one account you can only convert **33** PDFs. However, this also means you have very little room to play around with this API, unless you have an extra email-address, so you need to be very careful when coding to communicate with this API. \n",
    "\n",
    "Moreover, the API only keeps the converted files for one day with a free account, so make sure you do this part in one go.\n",
    "\n",
    "**Note: Using the Zamzar API grants a bonus of 10 marks. This will help if you are not able to complete this assignment, or it can be used up in a later assignment if you get 110/100 marks in this one.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another extremely simple API is the [PDF Tables](https://pdftables.com) API which is much simpler to use than the Zamzar API, however does not allow you to check the job for completion or for any intermediate steps. Moreover, this requires the installation of a library. Once again, they allow only 50 versions for free, but that is enough conversions for us. This [blog post](https://pdftables.com/blog/pdf-to-excel-with-python) will help you figure out how to convert the PDF to CSV using Python.\n",
    "\n",
    "The cons of this API is that it will not really teach you any proper API communcation through requests since you do not have to navigate through any requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.248651"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests.auth import HTTPBasicAuth as HBA\n",
    "import glob\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  3979788\n",
      "ID:  3979789\n",
      "ID:  3979790\n",
      "ID:  3979791\n",
      "ID:  3979792\n",
      "ID:  3979794\n",
      "ID:  3979796\n",
      "ID:  3979797\n",
      "ID:  3979799\n",
      "ID:  3979801\n",
      "ID:  3979803\n",
      "ID:  3979804\n",
      "ID:  3979805\n",
      "ID:  3979806\n",
      "ID:  3979807\n",
      "ID:  3979808\n",
      "ID:  3979809\n",
      "ID:  3979810\n",
      "ID:  3979811\n",
      "ID:  3979813\n",
      "ID:  3979814\n",
      "ID:  3979815\n",
      "ID:  3979816\n",
      "ID:  3979817\n",
      "ID:  3979819\n",
      "ID:  3979820\n",
      "ID:  3979821\n",
      "ID:  3979823\n",
      "ID:  3979824\n",
      "ID:  3979827\n",
      "ID:  3979829\n",
      "ID:  3979831\n",
      "ID:  3979832\n",
      "ID:  3979833\n",
      "ID:  3979836\n",
      "ID:  3979837\n",
      "ID:  3979838\n",
      "ID:  3979840\n",
      "ID:  3979841\n",
      "ID:  3979843\n",
      "ID:  3979844\n",
      "ID:  3979846\n",
      "ID:  3979847\n",
      "ID:  3979848\n",
      "ID:  3979850\n",
      "ID:  3979851\n",
      "ID:  3979852\n",
      "ID:  3979853\n",
      "ID:  3979854\n",
      "ID:  3979855\n",
      "ID:  3979856\n",
      "ID:  3979857\n",
      "ID:  3979858\n",
      "ID:  3979859\n",
      "ID:  3979860\n",
      "ID:  3979861\n",
      "ID:  3979862\n",
      "ID:  3979863\n"
     ]
    }
   ],
   "source": [
    "pdfs_folder = './allPdfs/*.pdf'\n",
    "\n",
    "\n",
    "job_ids = []\n",
    "\n",
    "bakar_api = \"1ebe14564fe42d5cd16185dc688247add9e1226a\"\n",
    "hadi_api = \"2c534c54fcf004bae076553fac29837311c24c3b\"\n",
    "endpoint = \"https://sandbox.zamzar.com/v1/jobs\"\n",
    "\n",
    "\n",
    "target_format = \"csv\"\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_name in glob.glob(pdfs_folder):\n",
    "    source_file = file_name\n",
    "    file_content = {'source_file': open(source_file, 'rb')}\n",
    "    data_content = {'target_format': target_format}\n",
    "    if((os.path.getsize(file_name)/1000000) < 1.0 ):\n",
    "        res = requests.post(endpoint, data=data_content, files=file_content, auth=HBA(bakar_api, ''))\n",
    "        job_ids.append(res.json()['id'])\n",
    "    if(i == 32): \n",
    "        bakar_api = hadi_api\n",
    "    i = i + 1\n",
    "    \n",
    "    \n",
    "for i in range(len(job_ids)):\n",
    "    print(\"ID: \", job_ids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below this cell write the code to download the completed files. First check if a job_id's status is completed and wait until it is. After it has been completed, download the file and save it.\n",
    "\n",
    "The exact code required here is all in the documentation, the only additional task you have to do on your own is figure out a way to find out which file has just been received from the job_id, and name the local file.\n",
    "\n",
    "**Please look at the Example JSON response in the [documentation](https://developers.zamzar.com/docs) to learn how to figure out the filenames, job status etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-08-2018.csv  downloaded\n",
      "01-10-2018.csv  downloaded\n",
      "02-08-2018.csv  downloaded\n",
      "02-10-2018.csv  downloaded\n",
      "03-08-2018.csv  downloaded\n",
      "03-09-2018.csv  downloaded\n",
      "03-10-2018.csv  downloaded\n",
      "04-09-2018.csv  downloaded\n",
      "04-10-2018.csv  downloaded\n",
      "05-09-2018.csv  downloaded\n",
      "05-10-2018.csv  downloaded\n",
      "06-07-2018.csv  downloaded\n",
      "06-08-2018.csv  downloaded\n",
      "06-09-2018.csv  downloaded\n",
      "07-08-2018.csv  downloaded\n",
      "07-09-2018.csv  downloaded\n",
      "08-08-2018.csv  downloaded\n",
      "09-07-2018.csv  downloaded\n",
      "09-08-2018.csv  downloaded\n",
      "10-07-2018.csv  downloaded\n",
      "10-08-2018.csv  downloaded\n",
      "10-09-2018.csv  downloaded\n",
      "11-07-2018.csv  downloaded\n",
      "11-09-2018.csv  downloaded\n",
      "12-07-2018.csv  downloaded\n",
      "12-09-2018.csv  downloaded\n",
      "13-07-2018.csv  downloaded\n",
      "13-08-2018.csv  downloaded\n",
      "13-09-2018.csv  downloaded\n",
      "14-09-2018.csv  downloaded\n",
      "15-08-2018.csv  downloaded\n",
      "16-07-2018.csv  downloaded\n",
      "16-08-2018.csv  downloaded\n",
      "17-07-2018.csv  downloaded\n",
      "17-08-2018.csv  downloaded\n",
      "17-09-2018.csv  downloaded\n",
      "18-07-2018.csv  downloaded\n",
      "18-09-2018.csv  downloaded\n",
      "19-07-2018.csv  downloaded\n",
      "19-09-2018.csv  downloaded\n",
      "20-07-2018.csv  downloaded\n",
      "20-08-2018.csv  downloaded\n",
      "23-07-2018.csv  downloaded\n",
      "24-07-2018.csv  downloaded\n",
      "24-08-2018.csv  downloaded\n",
      "24-09-2018.csv  downloaded\n",
      "25-09-2018.csv  downloaded\n",
      "26-07-2018.csv  downloaded\n",
      "26-09-2018.csv  downloaded\n",
      "27-07-2018.csv  downloaded\n",
      "27-09-2018.csv  downloaded\n",
      "28-08-2018.csv  downloaded\n",
      "28-09-2018.csv  downloaded\n",
      "29-08-2018.csv  downloaded\n",
      "30-07-2018.csv  downloaded\n",
      "30-08-2018.csv  downloaded\n",
      "31-07-2018.csv  downloaded\n",
      "31-08-2018.csv  downloaded\n"
     ]
    }
   ],
   "source": [
    "## Your code goes here ##\n",
    "newpath = r'./allCSVs'\n",
    "\n",
    "bakar_api = \"1ebe14564fe42d5cd16185dc688247add9e1226a\"\n",
    "hadi_api = \"2c534c54fcf004bae076553fac29837311c24c3b\"\n",
    "api_key = bakar_api\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.mkdir(newpath)\n",
    "else:\n",
    "    print (\"Directory already exists\")\n",
    "\n",
    "for i in range(len(job_ids)):\n",
    "    if(i > 32):\n",
    "        api_key = hadi_api\n",
    "    while(1):\n",
    "        sleep(3)\n",
    "        job_id = job_ids[i]\n",
    "        endpoint2 = \"https://sandbox.zamzar.com/v1/jobs/{}\".format(job_id)\n",
    "        res2 = requests.get(endpoint2, auth=HTTPBasicAuth(api_key, ''))\n",
    "        if(res2.json()['finished_at'] != None ):\n",
    "            file_id = ((res2.json()['target_files'])[0])['id']\n",
    "            endpoint3 = \"https://sandbox.zamzar.com/v1/files/{}/content\".format(file_id)\n",
    "            resp1 = requests.get(endpoint3, stream = True , auth=HBA(api_key, ''))\n",
    "            filetodownload = (((res2.json()['source_file'])['name']).split('.'))[0] + \".csv\"\n",
    "            \n",
    "            try:\n",
    "                with open(\"allCSVs/\"+filetodownload, 'wb') as f:\n",
    "                    for chunk in resp1.iter_content(chunk_size=1024):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                            f.flush()\n",
    "\n",
    "                    print(filetodownload, \" downloaded\")\n",
    "                    break\n",
    "            except IOError:\n",
    "                print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Parsing the CSV File\n",
    "Marks: 35\n",
    "\n",
    "This is perhaps the most difficult part of the assignment, you have to follow a similar strategy to what you did the Udacity Lab 1. You can not simply use Pandas read_csv since the conversion is not perfect and there will be rows with different number of columns, which Pandas does not take care of.\n",
    "\n",
    "### **Main Task:**\n",
    "* Write a function that parses a CSV into a Pandas DataFrame\n",
    "* Each DataFrame should consist of three columns with headers Bank, Donor_Name, and Amount\n",
    "* The date should be retrieved from the given filename \n",
    "* The Donor_Name can be NaN, as it is in a lot of cases. But try to retrieve as much information as possible\n",
    "* Remove all \"Page of\" rows\n",
    "* Don't include the header rows (e.g. \"SUPREME COURT FUND....\") into the DataFrame\n",
    "* The Amount should be converted into a Pandas numeric at the end\n",
    "\n",
    "### Other info:\n",
    "Some important resources for this part are (you can choose any one tutorial that you feel is easy to understand, they all cover roughly the same content):\n",
    "* [RegEx Tutorial 1](https://www.regular-expressions.info/)\n",
    "* [RegEx Tutorial 2](https://regexone.com/lesson/introduction_abcs)\n",
    "* [RegEx Tutorial 3](https://www.rexegg.com/)\n",
    "* [RegEx Cheatsheat](https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285)\n",
    "* This [RegEx Editor](https://regex101.com/) is your best friend since you can test your expression separately on this\n",
    "\n",
    "You will probably have to use the CSV reader in order to get all the rows of the file. You can learn more about it using this [tutorial](https://www.alexkras.com/how-to-read-csv-file-in-python/).\n",
    "\n",
    "Some tips:\n",
    "* First find out how many columns are in each row\n",
    "* Print out rows which are longer than they should be (they should all be of length 3)\n",
    "* Try to find patterns in how the data is spread, and what common problems exist in all rows\n",
    "* Write some regex to try an extract the amount from the problem row and then:\n",
    "    * Put the amount as the third column\n",
    "    * Merge the rest of the string as a name of the donor in the 2nd column\n",
    "* Also check if the rows with 3 columns are correctly formatted or not, many of them would probably not be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re # To use regular expressions\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "currency4 = re.compile('(,*\\d{1,3},\\d{3}[,\\d{3}]*|,\\d{1,3}[^\\d])')\n",
    "currency5 = re.compile('\\d{1,3}')\n",
    "numexp = re.compile('\\\"?\\s*(\\d[\\d|,]*\\.?\\d{1,2})\\s*\\\"?|\\\"?\\s*(\\d)\\s*\\\"?')\n",
    "\n",
    "\n",
    "# example_file = './allCSVs/01-08-2018.csv' # Assuming the file is in the folder all_csvs and is named appropriately\n",
    "# This is one of the most problematic files which is why I have included this in the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(filename):\n",
    "    data = []\n",
    "    li = []\n",
    "    row1 = []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # skip header\n",
    "        for row in reader:\n",
    "            li.append(row)\n",
    "            row1.append(row[0])\n",
    "            row1.append(\",\".join(row[1:]))\n",
    "            data.append(row1)\n",
    "            row1 = []\n",
    "        return li,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveAmount(vals):\n",
    "#     print(vals)\n",
    "    am = \"\"\n",
    "    if(len(vals)<4):\n",
    "        am = currency5.findall(vals)\n",
    "    else:\n",
    "        am = currency4.findall(vals)\n",
    "    new_am = \"\"\n",
    "    if(len(am) == 1):\n",
    "        if(vals[vals.find(am[0]) - 1].isdigit() == True and vals[vals.find(am[0])] != ','):\n",
    "            new_am = \"Nan\"\n",
    "            return(new_am, '')\n",
    "        else:\n",
    "            new_am = am[0].replace(',', '').replace('/','')\n",
    "            if(len(new_am) <= 9):\n",
    "                return(new_am, am[0])\n",
    "            else:\n",
    "                new_am = \"Nan\"\n",
    "                return(new_am, '')\n",
    "                \n",
    "    else:\n",
    "        new_am = \"Nan\"\n",
    "        return (new_am, '')\n",
    "        \n",
    "def giveAandR(remaining):\n",
    "    matlooba = numexp.findall(remaining)\n",
    "    newxyz = \"\"\n",
    "    for i in matlooba:\n",
    "        newxyz += i[0]+\"/\"\n",
    "    return giveAmount(newxyz)\n",
    "\n",
    "\n",
    "def retNameAndAmount(val):\n",
    "    orig = val\n",
    "    amountFinal, toRemove = giveAandR(val)\n",
    "    orig = orig.replace(toRemove, '')\n",
    "    return orig, amountFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcall(filename):\n",
    "    resultList,resultWord = test(filename)\n",
    "\n",
    "    true = 0\n",
    "    data = resultWord\n",
    "    dataForDataFrame = []\n",
    "    index = []\n",
    "    total = 0\n",
    "\n",
    "    lis = filename.split('\\\\')\n",
    "    date = lis[-1].split('.')[0]\n",
    "\n",
    "    for a in data:\n",
    "        if(a == ['Bank', 'Depositor Name,Amount']):\n",
    "            true = 1\n",
    "            continue\n",
    "        if(true == 1):\n",
    "            bankname = a[0]\n",
    "            if(len(bankname) != 0):\n",
    "                last_word = (bankname.split())[-1]\n",
    "                first_word = (bankname.split())[0]\n",
    "                if(last_word == 'Total'):\n",
    "                    continue\n",
    "                if(first_word == \"Page\" or first_word ==\"page\" or first_word == \"PAGE\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    remaining = a[1]\n",
    "                    dataitem = []\n",
    "                    dataitem.append(bankname)\n",
    "                    name,amount = retNameAndAmount(remaining)\n",
    "                    dataitem.append(name)\n",
    "                    dataitem.append(pd.to_numeric(amount, errors=\"coerce\"))\n",
    "                    dataitem.append(date)\n",
    "                    dataForDataFrame.append(dataitem)\n",
    "                    total+=1\n",
    "                    index.append(total)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return (dataForDataFrame,index)\n",
    "    \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, remove headers and convert all amounts to Numeric; if it can't be converted it needs to be NaN\n",
    "def read_csv(filename):\n",
    "#     print(filename)\n",
    "    filaname = filename.replace('\\\\', '/')\n",
    "    raw_headers = ['Bank', 'Donor Name','Amount','Date']\n",
    "    \n",
    "    raw_data, raw_indexes = funcall(filename)\n",
    "    \n",
    "    df = pd.DataFrame(raw_data,raw_indexes,raw_headers)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "# print(read_csv(example_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Importing Full Dataset\n",
    "Marks: 10 \n",
    "\n",
    "The only additional task in this part is to:\n",
    "* Run the parser on all the files\n",
    "* For each file **add a 'Date' column, which should be inferred from the filename**\n",
    "* Concatenate each DataFrame into one large DataFrame. *Hint: concat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank</th>\n",
       "      <th>Donor Name</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>SALMA HAMID,</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>TEHREEM SUBHAN,</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>AMINA NAZ,</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>HASSAN MUNIR,500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>IMAM BAKHSH,200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>FIRST MICRO FINANCE BANK,</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>GC UNIVERSITY FSD,</td>\n",
       "      <td>2398014.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>PAKISTAN MISSION UK,</td>\n",
       "      <td>2683838.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>MULTIPLE DONORS,100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>SALAH UD DIN,</td>\n",
       "      <td>35770.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>M AKHTER AND FAMILY,</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>KASHIF RASOOL,</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>M NASIR,500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>MUHAMMAD FAROOQ,500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SBP BSC</td>\n",
       "      <td>IRFAN ALI BHAKAKR,500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>MUHAMMAD ZUBAIR 0117,100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>MUHAMMAD ZAHEER ALAM 0117,500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>MUHAMMAD FAISAL IRSHAD 0117</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AL BARAKA BANK (PAKISTAN) LTD</td>\n",
       "      <td>SAMIA MALIK 0117</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>ABDUL FATAH,6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>SHAHID AHMED,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>HAFIZA IQRA ISHTIAQ,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>MUHAMMAD FARRUKH BASHEER,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>AFTAB JAMIL,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>SHAFQAT HAYAT,</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>SYED KAZIM HUSSAIN,</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>MUHAMMAD NADEEM ABBAS,</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>abdul hameed,</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>MISHAL,</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Allied Bank Limited</td>\n",
       "      <td>MUHAMMAD ROHAN,</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31-08-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154782</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>EKERMA JAVEED,6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154783</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>NAYYAR NAWAZ,5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154784</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>ADEEL TAHIR,3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154785</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>MEHMOOD AMJAD,1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154786</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>MUHAMMAD AFAQ,1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154787</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>MEHMOOD AMJAD,1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154788</th>\n",
       "      <td>United Bank Limited</td>\n",
       "      <td>MEHMOOD AMJAD,1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154789</th>\n",
       "      <td>United Bank Limited Overseas Branches PAKISTAN...</td>\n",
       "      <td>.17,</td>\n",
       "      <td>2866883.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154790</th>\n",
       "      <td>United Bank Limited Overseas Branches PAKISTAN...</td>\n",
       "      <td>.19,</td>\n",
       "      <td>299290.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154791</th>\n",
       "      <td>United Bank Limited Overseas Branches SHAHID A...</td>\n",
       "      <td>.63,</td>\n",
       "      <td>251962.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154792</th>\n",
       "      <td>United Bank Limited Overseas Branches HAJIALLA...</td>\n",
       "      <td>.38,</td>\n",
       "      <td>186971.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154793</th>\n",
       "      <td>United Bank Limited Overseas Branches SHAHZAD ...</td>\n",
       "      <td>.38,</td>\n",
       "      <td>186971.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154794</th>\n",
       "      <td>United Bank Limited Overseas Branches NAEEM AK...</td>\n",
       "      <td>.01,</td>\n",
       "      <td>124081.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154795</th>\n",
       "      <td>United Bank Limited Overseas Branches NADEEM A...</td>\n",
       "      <td>.79,</td>\n",
       "      <td>118981.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154796</th>\n",
       "      <td>United Bank Limited Overseas Branches SHAHID I...</td>\n",
       "      <td>.79,</td>\n",
       "      <td>118981.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154797</th>\n",
       "      <td>United Bank Limited Overseas Branches AAMIR KARIM</td>\n",
       "      <td>.83,</td>\n",
       "      <td>112182.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154798</th>\n",
       "      <td>United Bank Limited Overseas Branches MUHAMMAD...</td>\n",
       "      <td>,.63</td>\n",
       "      <td>61190.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154799</th>\n",
       "      <td>United Bank Limited Overseas Branches ZAHIDULL...</td>\n",
       "      <td>,.26</td>\n",
       "      <td>50550.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154800</th>\n",
       "      <td>United Bank Limited Overseas Branches HASSAN I...</td>\n",
       "      <td>,.80</td>\n",
       "      <td>33994.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154801</th>\n",
       "      <td>United Bank Limited Overseas Branches MOHD HAF...</td>\n",
       "      <td>,.80</td>\n",
       "      <td>33994.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154802</th>\n",
       "      <td>United Bank Limited Overseas Branches MUHAMMAD...</td>\n",
       "      <td>,.40</td>\n",
       "      <td>16997.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154803</th>\n",
       "      <td>United Bank Limited Overseas Branches MUHAMAMD...</td>\n",
       "      <td>,.40</td>\n",
       "      <td>16997.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154804</th>\n",
       "      <td>United Bank Limited Overseas Branches QURATULA...</td>\n",
       "      <td>,.40</td>\n",
       "      <td>16997.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154805</th>\n",
       "      <td>United Bank Limited Overseas Branches BASIT HA...</td>\n",
       "      <td>,,,.40,</td>\n",
       "      <td>16997.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154806</th>\n",
       "      <td>United Bank Limited Overseas Branches SAUD AFZ...</td>\n",
       "      <td>,,,.92,</td>\n",
       "      <td>13597.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154807</th>\n",
       "      <td>United Bank Limited Overseas Branches TARIQ FI...</td>\n",
       "      <td>,,,.45,</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154808</th>\n",
       "      <td>United Bank Limited Overseas Branches NAJIA AKBAR</td>\n",
       "      <td>,,,.44,</td>\n",
       "      <td>3637.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154809</th>\n",
       "      <td>Zarai Taraqiati Bank Ltd</td>\n",
       "      <td>M SHAFIQ, KHURRAM , AKARAM,SHAUKAT ALI,AND,KHA...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154810</th>\n",
       "      <td>Zarai Taraqiati Bank Ltd</td>\n",
       "      <td>JAN MOHAMMAD,,,,500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154811</th>\n",
       "      <td>Zarai Taraqiati Bank Ltd</td>\n",
       "      <td>M NAUMAN,,,,200.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-10-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154812 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Bank  \\\n",
       "0                                                 SBP BSC   \n",
       "1                                                 SBP BSC   \n",
       "2                                                 SBP BSC   \n",
       "3                                                 SBP BSC   \n",
       "4                                                 SBP BSC   \n",
       "5                                                 SBP BSC   \n",
       "6                                                 SBP BSC   \n",
       "7                                                 SBP BSC   \n",
       "8                                                 SBP BSC   \n",
       "9                                                 SBP BSC   \n",
       "10                                                SBP BSC   \n",
       "11                                                SBP BSC   \n",
       "12                                                SBP BSC   \n",
       "13                                                SBP BSC   \n",
       "14                                                SBP BSC   \n",
       "15                          AL BARAKA BANK (PAKISTAN) LTD   \n",
       "16                          AL BARAKA BANK (PAKISTAN) LTD   \n",
       "17                          AL BARAKA BANK (PAKISTAN) LTD   \n",
       "18                          AL BARAKA BANK (PAKISTAN) LTD   \n",
       "19                                    Allied Bank Limited   \n",
       "20                                    Allied Bank Limited   \n",
       "21                                    Allied Bank Limited   \n",
       "22                                    Allied Bank Limited   \n",
       "23                                    Allied Bank Limited   \n",
       "24                                    Allied Bank Limited   \n",
       "25                                    Allied Bank Limited   \n",
       "26                                    Allied Bank Limited   \n",
       "27                                    Allied Bank Limited   \n",
       "28                                    Allied Bank Limited   \n",
       "29                                    Allied Bank Limited   \n",
       "...                                                   ...   \n",
       "154782                                United Bank Limited   \n",
       "154783                                United Bank Limited   \n",
       "154784                                United Bank Limited   \n",
       "154785                                United Bank Limited   \n",
       "154786                                United Bank Limited   \n",
       "154787                                United Bank Limited   \n",
       "154788                                United Bank Limited   \n",
       "154789  United Bank Limited Overseas Branches PAKISTAN...   \n",
       "154790  United Bank Limited Overseas Branches PAKISTAN...   \n",
       "154791  United Bank Limited Overseas Branches SHAHID A...   \n",
       "154792  United Bank Limited Overseas Branches HAJIALLA...   \n",
       "154793  United Bank Limited Overseas Branches SHAHZAD ...   \n",
       "154794  United Bank Limited Overseas Branches NAEEM AK...   \n",
       "154795  United Bank Limited Overseas Branches NADEEM A...   \n",
       "154796  United Bank Limited Overseas Branches SHAHID I...   \n",
       "154797  United Bank Limited Overseas Branches AAMIR KARIM   \n",
       "154798  United Bank Limited Overseas Branches MUHAMMAD...   \n",
       "154799  United Bank Limited Overseas Branches ZAHIDULL...   \n",
       "154800  United Bank Limited Overseas Branches HASSAN I...   \n",
       "154801  United Bank Limited Overseas Branches MOHD HAF...   \n",
       "154802  United Bank Limited Overseas Branches MUHAMMAD...   \n",
       "154803  United Bank Limited Overseas Branches MUHAMAMD...   \n",
       "154804  United Bank Limited Overseas Branches QURATULA...   \n",
       "154805  United Bank Limited Overseas Branches BASIT HA...   \n",
       "154806  United Bank Limited Overseas Branches SAUD AFZ...   \n",
       "154807  United Bank Limited Overseas Branches TARIQ FI...   \n",
       "154808  United Bank Limited Overseas Branches NAJIA AKBAR   \n",
       "154809                           Zarai Taraqiati Bank Ltd   \n",
       "154810                           Zarai Taraqiati Bank Ltd   \n",
       "154811                           Zarai Taraqiati Bank Ltd   \n",
       "\n",
       "                                               Donor Name     Amount  \\\n",
       "0                                            SALMA HAMID,   100000.0   \n",
       "1                                         TEHREEM SUBHAN,     4000.0   \n",
       "2                                              AMINA NAZ,     1000.0   \n",
       "3                                        HASSAN MUNIR,500        NaN   \n",
       "4                                         IMAM BAKHSH,200        NaN   \n",
       "5                               FIRST MICRO FINANCE BANK,     1110.0   \n",
       "6                                      GC UNIVERSITY FSD,  2398014.0   \n",
       "7                                    PAKISTAN MISSION UK,  2683838.0   \n",
       "8                                     MULTIPLE DONORS,100        NaN   \n",
       "9                                           SALAH UD DIN,    35770.0   \n",
       "10                                   M AKHTER AND FAMILY,     1500.0   \n",
       "11                                         KASHIF RASOOL,     2500.0   \n",
       "12                                            M NASIR,500        NaN   \n",
       "13                                    MUHAMMAD FAROOQ,500        NaN   \n",
       "14                                  IRFAN ALI BHAKAKR,500        NaN   \n",
       "15                               MUHAMMAD ZUBAIR 0117,100        NaN   \n",
       "16                          MUHAMMAD ZAHEER ALAM 0117,500        NaN   \n",
       "17                            MUHAMMAD FAISAL IRSHAD 0117     4500.0   \n",
       "18                                       SAMIA MALIK 0117     5000.0   \n",
       "19                                          ABDUL FATAH,6        NaN   \n",
       "20                                          SHAHID AHMED,       10.0   \n",
       "21                                   HAFIZA IQRA ISHTIAQ,       10.0   \n",
       "22                              MUHAMMAD FARRUKH BASHEER,       10.0   \n",
       "23                                           AFTAB JAMIL,       10.0   \n",
       "24                                         SHAFQAT HAYAT,       20.0   \n",
       "25                                    SYED KAZIM HUSSAIN,       20.0   \n",
       "26                                 MUHAMMAD NADEEM ABBAS,       33.0   \n",
       "27                                          abdul hameed,       50.0   \n",
       "28                                                MISHAL,       50.0   \n",
       "29                                        MUHAMMAD ROHAN,       50.0   \n",
       "...                                                   ...        ...   \n",
       "154782                                 EKERMA JAVEED,6.00        NaN   \n",
       "154783                                  NAYYAR NAWAZ,5.00        NaN   \n",
       "154784                                   ADEEL TAHIR,3.00        NaN   \n",
       "154785                                 MEHMOOD AMJAD,1.00        NaN   \n",
       "154786                                 MUHAMMAD AFAQ,1.00        NaN   \n",
       "154787                                 MEHMOOD AMJAD,1.00        NaN   \n",
       "154788                                 MEHMOOD AMJAD,1.00        NaN   \n",
       "154789                                               .17,  2866883.0   \n",
       "154790                                               .19,   299290.0   \n",
       "154791                                               .63,   251962.0   \n",
       "154792                                               .38,   186971.0   \n",
       "154793                                               .38,   186971.0   \n",
       "154794                                               .01,   124081.0   \n",
       "154795                                               .79,   118981.0   \n",
       "154796                                               .79,   118981.0   \n",
       "154797                                               .83,   112182.0   \n",
       "154798                                               ,.63    61190.0   \n",
       "154799                                               ,.26    50550.0   \n",
       "154800                                               ,.80    33994.0   \n",
       "154801                                               ,.80    33994.0   \n",
       "154802                                               ,.40    16997.0   \n",
       "154803                                               ,.40    16997.0   \n",
       "154804                                               ,.40    16997.0   \n",
       "154805                                            ,,,.40,    16997.0   \n",
       "154806                                            ,,,.92,    13597.0   \n",
       "154807                                            ,,,.45,    10130.0   \n",
       "154808                                            ,,,.44,     3637.0   \n",
       "154809  M SHAFIQ, KHURRAM , AKARAM,SHAUKAT ALI,AND,KHA...     3000.0   \n",
       "154810                             JAN MOHAMMAD,,,,500.00        NaN   \n",
       "154811                                 M NAUMAN,,,,200.00        NaN   \n",
       "\n",
       "              Date  \n",
       "0       31-08-2018  \n",
       "1       31-08-2018  \n",
       "2       31-08-2018  \n",
       "3       31-08-2018  \n",
       "4       31-08-2018  \n",
       "5       31-08-2018  \n",
       "6       31-08-2018  \n",
       "7       31-08-2018  \n",
       "8       31-08-2018  \n",
       "9       31-08-2018  \n",
       "10      31-08-2018  \n",
       "11      31-08-2018  \n",
       "12      31-08-2018  \n",
       "13      31-08-2018  \n",
       "14      31-08-2018  \n",
       "15      31-08-2018  \n",
       "16      31-08-2018  \n",
       "17      31-08-2018  \n",
       "18      31-08-2018  \n",
       "19      31-08-2018  \n",
       "20      31-08-2018  \n",
       "21      31-08-2018  \n",
       "22      31-08-2018  \n",
       "23      31-08-2018  \n",
       "24      31-08-2018  \n",
       "25      31-08-2018  \n",
       "26      31-08-2018  \n",
       "27      31-08-2018  \n",
       "28      31-08-2018  \n",
       "29      31-08-2018  \n",
       "...            ...  \n",
       "154782  01-10-2018  \n",
       "154783  01-10-2018  \n",
       "154784  01-10-2018  \n",
       "154785  01-10-2018  \n",
       "154786  01-10-2018  \n",
       "154787  01-10-2018  \n",
       "154788  01-10-2018  \n",
       "154789  01-10-2018  \n",
       "154790  01-10-2018  \n",
       "154791  01-10-2018  \n",
       "154792  01-10-2018  \n",
       "154793  01-10-2018  \n",
       "154794  01-10-2018  \n",
       "154795  01-10-2018  \n",
       "154796  01-10-2018  \n",
       "154797  01-10-2018  \n",
       "154798  01-10-2018  \n",
       "154799  01-10-2018  \n",
       "154800  01-10-2018  \n",
       "154801  01-10-2018  \n",
       "154802  01-10-2018  \n",
       "154803  01-10-2018  \n",
       "154804  01-10-2018  \n",
       "154805  01-10-2018  \n",
       "154806  01-10-2018  \n",
       "154807  01-10-2018  \n",
       "154808  01-10-2018  \n",
       "154809  01-10-2018  \n",
       "154810  01-10-2018  \n",
       "154811  01-10-2018  \n",
       "\n",
       "[154812 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('./allCSVs/*.csv')\n",
    "\n",
    "dataf1 = []\n",
    "dataf2 = []\n",
    "\n",
    "dataf1 = read_csv(files[0])\n",
    "full_data = read_csv(files[1])\n",
    "\n",
    "full_data = pd.concat([dataf1, full_data], ignore_index=True)\n",
    "\n",
    "for i in range(2, len(files)):\n",
    "    dataf1 = read_csv(files[i])\n",
    "    full_data = pd.concat([dataf1, full_data], ignore_index=True)\n",
    "    \n",
    "# pd.DataFrame(dataf1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_data\n",
    "\n",
    "# print (full_data.head())\n",
    "# print (full_data.shape)\n",
    "# print (full_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Data Integrity Checks\n",
    "Marks: 20\n",
    "\n",
    "* How many NaN values are there in each column? Why are they there? \n",
    "* What are the maximum and minimum values, is there anything peculiar about the max values?\n",
    "* Are there any rows which are not NaN but should still be a different DataFrame altogether?\n",
    "* Should these problem rows be removed? Can they be useful in other ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank              0\n",
       "Donor Name        0\n",
       "Amount        50691\n",
       "Date              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isna().sum()\n",
    "\n",
    "\n",
    "# Number of NaN values = 50691.\n",
    "# They are there because the csv files are not propperly formatted and there are many different kinds of values which makes\n",
    "# difficult to extract the amount from the rows. For example, mobile numbers and amounts are written together and we cannot\n",
    "# be sure from where exactly the amount value starts from the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank               SBP BSC\n",
       "Donor Name    PAK ARMY,.00\n",
       "Amount         5.82072e+08\n",
       "Date            11-09-2018\n",
       "Name: 106680, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.max()\n",
    "\n",
    "full_data.iloc[full_data['Amount'].idxmax()]\n",
    "\n",
    "#Pakistan Army gave the maximum amount which is displayed when the cell is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank             United Bank Limited\n",
       "Donor Name    ADNAN ALI TID 11183900\n",
       "Amount                             1\n",
       "Date                      30-07-2018\n",
       "Name: 9245, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.iloc[full_data['Amount'].idxmin()]\n",
    "\n",
    "#Minimum Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 and 4\n",
    "\n",
    "* Are there any rows which are not NaN but should still be a different DataFrame altogether?\n",
    "\n",
    "In the bankname and donor name columns there are alot of values which mean nothing. These are because in some rows in the data there are values without names or amounts.\n",
    "* Should these problem rows be removed? Can they be useful in other ways?\n",
    "\n",
    "Yes these problem rows should be removed. Data should be cleaned as much as possible to ensure data integrity and hence the accuracy of the results that we use in data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
